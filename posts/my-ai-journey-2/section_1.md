# 1. The "Big Shift": Navigating the Fog

Nobody claims anymore about JS Frameworks Hype... Let's say we have 15 Frontend JS Frameworks since Angular in 2012, how many models, how many tools are availabale since the last three years? After the JavaScript fatigue, are we entering the **AI fatigue**? 

I’m relatively new to this industry, and this rapid evolution induces some real fear and discomfort. The visibility on "what skills will matter in 5 years" drops to zero. This feeling is well resumed in "Everybody Else Is Doing It, So Why Can't I?" from .... https://www.linkedin.com/pulse/fear-learning-vancouver-clarifying-journey-realities-rand-hendriksen-xzsbc/

### Listening to seasoned developers
But there is a way to see over the fog: listen to the people who have seen previous shifts.

When I heard industry veterans like **Martin Fowler** and **Gergely Orosz** discuss this[^1], something clicked. They weren't just nodding along to the hype; they were acknowledging that this feels like the **biggest technology shift of their professional careers**.

That's the kind relief i've been waiting for. It confirmed that the confusion isn't a "junior" problem. It’s an "industry" problem. **This is a big shift for everyone.** 

### Evaluate the shift

Once you accept that *everyone* is struggling, you can stop panicking and start evaluating the shift for what it is. What makes this shift so different?

**1. The Paradigm Shift: Non-Determinism**
When you learn programming, or building a tech product, you write some expectations in specifications organic notes or formatted Epic and User Stories, but the coding phase is to reflect the expected behavior through determinist functions, classes and dependencies. Even when complexity increases and bring some chaos, you can still debug, and trace.

> "Because if you've ever looked at chaos theory, you understand that even very simple functions can yield very extreme results depending on the variability in the inputs"  (Humans in the Loop: Engineering Leadership in a Chaotic Industry https://www.infoq.com/presentations/ai-ml-jobs/ Michelle Rush)

This new world brings us non-deterministic assistants, when you could feel the fight to bring context to avoid dis-alignment of the Black box LLMs, even worst on a team level. It redefining the way we are interacting with code, new skills, new tools, new way of logging, ...

(The Paradigm Shift: From Predictable Code to Unpredictable Agents - Google Paper)

**2. The "Intelligence" Trap**

Morten Rand-Hendriksen argues that the word "Intelligence" gives these tools too much credit. We should think of them as **Assisted Technologies**[^2]. In fact giving the word "intelligence ", or Learning, Thinking, reasoning, training are human metaphors. It is like the human bias of anthopomorphize anything that looks like natural or human.

> We want to understand these things as people. When you type a question to ChatGPT and it types back the answer in complete sentences, it feels like there must be a little guy in there doing the typing. ... We can’t help it; humans are hopeless anthropomorphizers. https://www.experimental-history.com/p/bag-of-words-have-mercy-on-us, Adam Mastroianni

Somekind related with Pareidolia (https://en.wikipedia.org/wiki/Pareidolia), when you see a face in a cloud. Our brains are wired to find patterns—like. This kind psychological effect makes us trust the machine more than we should. We project intent where there is only math.

Like Morten said when you don't understand anymore what it's human and what it is articificial, it generates anxiety. 


**3. The Irony of Automation**
If using AI feels exhausting, there is a reason. Michelle Rush called it the **Irony of Automation**[^3]: Partial automation makes the residual job _harder_. 

> When you automate the easy parts, what’s left are the hard judgments, debugging edge cases, and maintenance.

*   The AI automates the easy parts (boilerplate, syntax, common patterns).
*   The human is left with the hard parts (judgment, edge cases, debugging complex failures).
*   **Result:** Your "typing" time goes down, but your "thinking intensity" goes up.


**4. The Foundation Remains***

This leads to the ultimate reassurance: **Things that don't change.**

The foundation of engineering is more critical now than ever. As Simon Willison notes, the skills that make someone a senior engineer—designing systems, managing complexity, knowing what to automate vs. hand-code—are exactly what yield the best outcomes with AI[^4].

If you have weak foundations, AI just helps you build a bad system faster. If you have strong foundations, it becomes a lever.  

---
[^1]: **Martin Fowler & Gergely Orosz**: "It feels by far the biggest technology innovation changes coming in." — *The Pragmatic Engineer*
[^2]: **Morten Rand-Hendriksen**: "We are giving AI too much credit... We see two black dots and think it's a face." — *TEDxSurrey*
[^3]: **Michelle Rush**: "When you automate the easy parts, what’s left are the hard judgments, debugging edge cases, and maintenance." — *QCon*
[^4]: **Simon Willison**: "Almost everything that makes someone a senior engineer is what now yields the best outcomes with AI."
